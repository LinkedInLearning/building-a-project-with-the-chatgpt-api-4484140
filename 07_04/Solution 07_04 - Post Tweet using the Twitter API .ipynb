{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa8cd98",
   "metadata": {},
   "source": [
    "# Building a Project with the ChatGPT API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c606f61f",
   "metadata": {},
   "source": [
    "## Integrate with Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5767de",
   "metadata": {},
   "source": [
    "## 07_04 - Solution - Post Tweet using the Twitter API \n",
    "\n",
    "### In this hands-on challenge, you'll tweet the generated summary and image using the Twitter API\n",
    "\n",
    "#### The extra credit portion of this challenge is to turn this code into an API using Flask. See notebooks Flask API (with Server) and Flask API (as Client) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48e61b",
   "metadata": {},
   "source": [
    "### Import the libraries and enviornment file to gain access to the Open API Key\n",
    "#### The key can be generated here: https://platform.openai.com/account/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70841de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai #needed for error handling\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5387008",
   "metadata": {},
   "source": [
    "### Authenticate to the API using the API Key\n",
    "#### Pull from environment variables or use openai.api_key = (\"your_key_here\") to hardcode the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf566e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY']  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4fb6162",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "#sets the persona for the AI assistant using a system message\n",
    "context = [{'role':'system', 'content':\"\"\"You are a friendly AI assistant that \n",
    "                                              helps compose professional-sounding tweets \n",
    "                                              for Twitter that often go viral based on a \n",
    "                                              website I provide. You will provide a summary \n",
    "                                              of the website in 50 words or less.\"\"\"\n",
    "            }]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "343f9d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each interation with the AI assistant is a new session so the entire chat/message history, \n",
    "# including user prompts and assistant responses must be included in each exchange with the\n",
    "# model/assistant so that it \"remembers\"\n",
    "\n",
    "def collect_messages(role, message): #keeps track of the message exchange between user and assistant\n",
    "    context.append({'role': role, 'content':f\"{message}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c3c3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sends the prompts to the model for a completion/response\n",
    "\n",
    "def get_completion(temperature=0): \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=TEXT_MODEL,\n",
    "            messages=context, \n",
    "            temperature=temperature, \n",
    "        )\n",
    "\n",
    "        print(\"\\n Assistant: \", response.choices[0].message.content, \"\\n\")\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "    except openai.APIError as e:\n",
    "        print(e.http_status)\n",
    "        print(e.error)\n",
    "        return e.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "106c7350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create images from scratch based on the website summary\n",
    "\n",
    "def generate_image(summary):\n",
    "    print(summary)\n",
    "    \n",
    "    try:\n",
    "        response = client.images.generate(\n",
    "          model=\"dall-e-3\",\n",
    "          prompt=summary,\n",
    "          size=\"1024x1024\",\n",
    "          quality=\"standard\",\n",
    "          n=1, #select the number of images you want generated\n",
    "        )\n",
    "        \n",
    "        image_url = response.data[0].url #URLs will expire after an hour\n",
    "\n",
    "        return image_url\n",
    "    except openai.APIError as e:\n",
    "        print(e.http_status)\n",
    "        print(e.error)\n",
    "        return e.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebca5506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Assistant:  Sure, please provide me with the website you would like me to summarize. \n",
      "\n",
      "User: http://www.amazon.com/sagemaker\n",
      "\n",
      " Assistant:  Amazon SageMaker is a comprehensive machine learning service provided by Amazon Web Services (AWS). It allows users to build, train, and deploy machine learning models at scale. With a wide range of tools and capabilities, SageMaker simplifies the process of developing and deploying machine learning models for various applications. \n",
      "\n",
      "User: Can you optimize the summary in 10 words in order to generate an image?\n",
      "\n",
      " Assistant:  Amazon SageMaker: AWS machine learning service for building, training, deploying models. \n",
      "\n",
      "User: exit\n",
      "\n",
      " Goodbye\n"
     ]
    }
   ],
   "source": [
    "#Start the conversation between the user and the AI assistant/chatbot\n",
    "    \n",
    "while True:\n",
    "    summary = get_completion()\n",
    "    \n",
    "    collect_messages('assistant', summary) #stores the response from the AI assistant\n",
    "    \n",
    "    user_prompt = input('User: ') #input box for entering prompt\n",
    "    \n",
    "    if user_prompt == 'exit': #end the conversation with the AI assistant\n",
    "        print(\"\\n Goodbye\")\n",
    "        break\n",
    "\n",
    "    collect_messages('user', user_prompt) #stores the user prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "752b0110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon SageMaker: AWS machine learning service for building, training, deploying models.\n"
     ]
    }
   ],
   "source": [
    "url = generate_image(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc196d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-RZLvEijW4GW0KmC3rLIAjZlu/user-GjAVqpM2XyDru7SeUyCqCIh7/img-8uVBclcPGCaW1FefijjvYQyK.png?st=2023-11-12T14%3A33%3A49Z&se=2023-11-12T16%3A33%3A49Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-12T13%3A44%3A14Z&ske=2023-11-13T13%3A44%3A14Z&sks=b&skv=2021-08-06&sig=k0zO4Izhq1sZNCZFz45Byx3YxZhl2ZmJ1Kqiut66/NQ%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display image inline\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd26130e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tweepy in /Users/keshawilliams/Library/Python/3.8/lib/python/site-packages (4.14.0)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /Users/keshawilliams/Library/Python/3.8/lib/python/site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /Users/keshawilliams/Library/Python/3.8/lib/python/site-packages (from tweepy) (2.31.0)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /Users/keshawilliams/Library/Python/3.8/lib/python/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/keshawilliams/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2.27.0->tweepy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/keshawilliams/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2.27.0->tweepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/keshawilliams/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/keshawilliams/Library/Python/3.8/lib/python/site-packages (from requests<3,>=2.27.0->tweepy) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1673aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import requests\n",
    "\n",
    "# Authenticate to Twitter API\n",
    "consumer_key = os.getenv(\"API_KEY\")\n",
    "consumer_secret = os.getenv(\"API_SECRET_KEY\")\n",
    "access_token = os.getenv(\"ACCESS_TOKEN\")   \n",
    "access_token_secret = os.getenv(\"ACCESS_TOKEN_SECRET_KEY\") \n",
    "\n",
    "#download image to notebook\n",
    "def download_image(imageURL):\n",
    "    print(\"downloading - \", imageURL)\n",
    "    \n",
    "    img_data = requests.get(imageURL).content\n",
    "    with open('dalle_image.jpg', 'wb') as handler:\n",
    "        handler.write(img_data)\n",
    "    \n",
    "    return \"dalle_image.jpg\"\n",
    "\n",
    "#upload image media using V1 of Twitter API\n",
    "def upload_image(image):\n",
    "    auth = tweepy.OAuth1UserHandler(\n",
    "       consumer_key,\n",
    "       consumer_secret,\n",
    "       access_token,\n",
    "       access_token_secret\n",
    "    )\n",
    "\n",
    "    api = tweepy.API(auth)\n",
    "    media = api.media_upload(filename=image) \n",
    "    \n",
    "    return media\n",
    "\n",
    "#send the tweet using V2 of the Twitter API\n",
    "def send_tweet(summary, image):\n",
    "    client = tweepy.Client(\n",
    "        consumer_key=consumer_key, consumer_secret=consumer_secret,\n",
    "        access_token=access_token, access_token_secret=access_token_secret\n",
    "    )\n",
    "\n",
    "    #upload image to Twitter servers and get the media metadata\n",
    "    media = upload_image(image)\n",
    "    media_ids = [media.media_id]\n",
    "    \n",
    "    #send the tweet\n",
    "    response = client.create_tweet(text=summary, media_ids=media_ids)\n",
    "    \n",
    "    print(f\"https://twitter.com/user/status/{response.data['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a72a005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading -  https://oaidalleapiprodscus.blob.core.windows.net/private/org-RZLvEijW4GW0KmC3rLIAjZlu/user-GjAVqpM2XyDru7SeUyCqCIh7/img-8uVBclcPGCaW1FefijjvYQyK.png?st=2023-11-12T14%3A33%3A49Z&se=2023-11-12T16%3A33%3A49Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-12T13%3A44%3A14Z&ske=2023-11-13T13%3A44%3A14Z&sks=b&skv=2021-08-06&sig=k0zO4Izhq1sZNCZFz45Byx3YxZhl2ZmJ1Kqiut66/NQ%3D\n"
     ]
    }
   ],
   "source": [
    "#download image to the notebook\n",
    "image_name = download_image(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcfaefa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://twitter.com/user/status/1723725825856479568\n"
     ]
    }
   ],
   "source": [
    "#send tweet\n",
    "send_tweet(summary, image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36777f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
